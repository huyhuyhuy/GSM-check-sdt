#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test file ƒë·ªÉ chuy·ªÉn ƒë·ªïi file WAV th√†nh text s·ª≠ d·ª•ng Speech-to-Text (STT)
Ph∆∞∆°ng ph√°p: Speech-to-Text (STT) - Ch√≠nh x√°c nh·∫•t

C√†i ƒë·∫∑t dependencies:
pip install SpeechRecognition pydub openai-whisper
pip install azure-cognitiveservices-speech (n·∫øu d√πng Azure)
"""

import os
import sys
import time
import wave
import json
from pathlib import Path
from typing import Optional, Dict, List, Tuple

# ==============================================================================
# PH∆Ø∆†NG PH√ÅP 1: GOOGLE SPEECH RECOGNITION (MI·ªÑN PH√ç)
# ==============================================================================

def google_speech_to_text(wav_file_path: str, language: str = "vi-VN") -> Dict:
    """
    Chuy·ªÉn ƒë·ªïi WAV th√†nh text s·ª≠ d·ª•ng Google Speech Recognition
    Mi·ªÖn ph√≠, ch√≠nh x√°c cao, c·∫ßn internet
    """
    try:
        import speech_recognition as sr
        
        # Kh·ªüi t·∫°o recognizer
        recognizer = sr.Recognizer()
        
        # ƒê·ªçc file WAV
        with sr.AudioFile(wav_file_path) as source:
            print(f"üéµ ƒêang ƒë·ªçc file: {wav_file_path}")
            
            # ƒêi·ªÅu ch·ªânh noise
            recognizer.adjust_for_ambient_noise(source, duration=0.5)
            
            # Thu audio
            audio = recognizer.record(source)
            
            print("üîç ƒêang nh·∫≠n di·ªán v·ªõi Google Speech Recognition...")
            
            # Nh·∫≠n di·ªán speech
            text = recognizer.recognize_google(
                audio, 
                language=language,
                show_all=False  # Ch·ªâ l·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t
            )
            
            return {
                "method": "Google Speech Recognition",
                "success": True,
                "text": text,
                "confidence": None,  # Google kh√¥ng tr·∫£ v·ªÅ confidence
                "language": language,
                "processing_time": None
            }
            
    except sr.UnknownValueError:
        return {
            "method": "Google Speech Recognition",
            "success": False,
            "error": "Kh√¥ng th·ªÉ nh·∫≠n di·ªán ƒë∆∞·ª£c speech",
            "text": None,
            "confidence": None,
            "language": language
        }
    except sr.RequestError as e:
        return {
            "method": "Google Speech Recognition",
            "success": False,
            "error": f"L·ªói k·∫øt n·ªëi Google: {str(e)}",
            "text": None,
            "confidence": None,
            "language": language
        }
    except Exception as e:
        return {
            "method": "Google Speech Recognition",
            "success": False,
            "error": f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}",
            "text": None,
            "confidence": None,
            "language": language
        }

# ==============================================================================
# PH∆Ø∆†NG PH√ÅP 2: OPENAI WHISPER (CH√çNH X√ÅC NH·∫§T)
# ==============================================================================
import whisper
import wave
import numpy as np
import resampy
def whisper_speech_to_text(wav_file_path: str, model_size: str = "small") -> Dict:
    try:

        wav_path = Path(wav_file_path).resolve()
        print(f"üéµ ƒêang t·∫£i Whisper model: {model_size}")
        print(f"üìÅ File path: {wav_path}")
        print(f"üìÅ File exists: {wav_path.exists()}")
        print(f" Current directory: {Path.cwd()}")

        if not wav_path.exists():
            return {
                "method": f"OpenAI Whisper ({model_size})",
                "success": False,
                "error": f"File kh√¥ng t·ªìn t·∫°i: {wav_path}",
                "text": None,
                "confidence": None,
                "language": "vi"
            }

        # ƒê·ªçc WAV
        print("üìñ ƒêang ƒë·ªçc file WAV...")
        with wave.open(str(wav_path), 'rb') as wf:
            ch      = wf.getnchannels()
            sw      = wf.getsampwidth()
            sr      = wf.getframerate()
            n_fr    = wf.getnframes()
            print(f"üìä Audio info: {ch} channels, {sw*8} bit, {sr} Hz, {n_fr} frames")
            raw = wf.readframes(n_fr)

        # bytes ‚Üí float32 array in [-1,1]
        if sw == 2:
            audio = np.frombuffer(raw, dtype=np.int16).astype(np.float32)/32768.0
        elif sw == 4:
            audio = np.frombuffer(raw, dtype=np.int32).astype(np.float32)/2147483648.0
        else:
            audio = np.frombuffer(raw, dtype=np.uint8).astype(np.float32)/128.0

        if ch == 2:
            audio = audio.reshape(-1,2).mean(axis=1)
            print("üîÑ Chuy·ªÉn stereo ‚Üí mono")

        print(f"‚úÖ ƒê√£ ƒë·ªçc audio: {len(audio)} samples, {len(audio)/sr:.2f}s")

        # Resample v·ªÅ 16k
        print("üîÑ ƒêang resample v·ªÅ 16 kHz...")
        if sr != 16000:
            audio = resampy.resample(audio, sr, 16000)
            print(f"‚úÖ ƒê√£ resample: {sr} -> 16000 Hz")
        else:
            print("‚úÖ File ƒë√£ 16 kHz")

        # Cast & normalize
        print("üîß ƒêang cast v√† normalize audio...")
        audio = audio.astype(np.float32)
        max_amp = np.max(np.abs(audio))
        if max_amp > 0:
            audio /= max_amp
        print(f"üîç Audio range: {audio.min():.6f} to {audio.max():.6f}")

        # Transcribe
        start = time.time()
        model = whisper.load_model("medium")
        print("üéôÔ∏è ƒêang nh·∫≠n di·ªán v·ªõi Whisper...")
        result = model.transcribe(
            audio,
            language="vi",
            task="transcribe",
            verbose=False,
            no_speech_threshold=0.7,
            logprob_threshold=-1.0
        )
        print("‚úÖ Whisper x·ª≠ l√Ω th√†nh c√¥ng!")

        return {
            "method": f"OpenAI Whisper ({model_size})",
            "success": True,
            "text": result["text"].strip(),
            "confidence": result.get("avg_logprob"),
            "language": result.get("language", "vi"),
            "processing_time": time.time() - start,
            "segments": result.get("segments", [])
        }

    except Exception as e:
        return {
            "method": f"OpenAI Whisper ({model_size})",
            "success": False,
            "error": f"L·ªói t·ªïng qu√°t: {e}",
            "text": None,
            "confidence": None,
            "language": "vi"
        }


# ==============================================================================
# PH∆Ø∆†NG PH√ÅP 3: AZURE SPEECH SERVICES (CHUY√äN NGHI·ªÜP)
# ==============================================================================

def azure_speech_to_text(wav_file_path: str, subscription_key: str, region: str) -> Dict:
    """
    Chuy·ªÉn ƒë·ªïi WAV th√†nh text s·ª≠ d·ª•ng Azure Speech Services
    Chuy√™n nghi·ªáp, ch√≠nh x√°c cao, c√≥ confidence score
    """
    try:
        import azure.cognitiveservices.speech as speechsdk
        
        # C·∫•u h√¨nh Azure Speech
        speech_config = speechsdk.SpeechConfig(
            subscription=subscription_key, 
            region=region
        )
        speech_config.speech_recognition_language = "vi-VN"
        
        # T·∫°o audio config
        audio_config = speechsdk.AudioConfig(filename=wav_file_path)
        
        # T·∫°o speech recognizer
        speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config, 
            audio_config=audio_config
        )
        
        print("üîç ƒêang nh·∫≠n di·ªán v·ªõi Azure Speech Services...")
        start_time = time.time()
        
        # Nh·∫≠n di·ªán speech
        result = speech_recognizer.recognize_once()
        
        processing_time = time.time() - start_time
        
        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            return {
                "method": "Azure Speech Services",
                "success": True,
                "text": result.text,
                "confidence": None,  # Azure kh√¥ng tr·∫£ v·ªÅ confidence tr·ª±c ti·∫øp
                "language": "vi-VN",
                "processing_time": processing_time,
                "reason": str(result.reason)
            }
        else:
            return {
                "method": "Azure Speech Services",
                "success": False,
                "error": f"Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c: {result.reason}",
                "text": None,
                "confidence": None,
                "language": "vi-VN"
            }
            
    except Exception as e:
        return {
            "method": "Azure Speech Services",
            "success": False,
            "error": f"L·ªói Azure: {str(e)}",
            "text": None,
            "confidence": None,
            "language": "vi-VN"
        }

# ==============================================================================
# PH∆Ø∆†NG PH√ÅP 4: HYBRID APPROACH - K·∫æT H·ª¢P NHI·ªÄU PH∆Ø∆†NG PH√ÅP
# ==============================================================================

def hybrid_speech_to_text(wav_file_path: str, 
                          use_google: bool = True,
                          use_whisper: bool = True,
                          use_azure: bool = False,
                          azure_key: str = "",
                          azure_region: str = "") -> Dict:
    """
    K·∫øt h·ª£p nhi·ªÅu ph∆∞∆°ng ph√°p STT ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
    """
    results = {}
    
    print("üöÄ B·∫Øt ƒë·∫ßu Hybrid Speech-to-Text Analysis...")
    print("=" * 60)
    
    # 1. Google Speech Recognition
    if use_google:
        print("\nüì± Ph∆∞∆°ng ph√°p 1: Google Speech Recognition")
        results['google'] = google_speech_to_text(wav_file_path)
        if results['google']['success']:
            print(f"‚úÖ K·∫øt qu·∫£: {results['google']['text']}")
        else:
            print(f"‚ùå L·ªói: {results['google']['error']}")
    
    # 2. OpenAI Whisper
    if use_whisper:
        print("\nü§ñ Ph∆∞∆°ng ph√°p 2: OpenAI Whisper")
        results['whisper'] = whisper_speech_to_text(wav_file_path, "small")
        if results['whisper']['success']:
            print(f"‚úÖ K·∫øt qu·∫£: {results['whisper']['text']}")
            print(f"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {results['whisper']['processing_time']:.2f}s")
        else:
            print(f"‚ùå L·ªói: {results['whisper']['error']}")
    
    # 3. Azure Speech Services
    if use_azure and azure_key and azure_region:
        print("\n‚òÅÔ∏è Ph∆∞∆°ng ph√°p 3: Azure Speech Services")
        results['azure'] = azure_speech_to_text(wav_file_path, azure_key, azure_region)
        if results['azure']['success']:
            print(f"‚úÖ K·∫øt qu·∫£: {results['azure']['text']}")
            print(f"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {results['azure']['processing_time']:.2f}s")
        else:
            print(f"‚ùå L·ªói: {results['azure']['error']}")
    
    # 4. Ph√¢n t√≠ch v√† quy·∫øt ƒë·ªãnh k·∫øt qu·∫£ cu·ªëi c√πng
    print("\n" + "=" * 60)
    print("üéØ PH√ÇN T√çCH K·∫æT QU·∫¢ CU·ªêI C√ôNG")
    print("=" * 60)
    
    final_result = analyze_hybrid_results(results)
    
    return {
        "individual_results": results,
        "final_result": final_result,
        "summary": create_summary(results)
    }

def analyze_hybrid_results(results: Dict) -> Dict:
    """
    Ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ nhi·ªÅu ph∆∞∆°ng ph√°p v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh cu·ªëi c√πng
    """
    successful_results = {}
    
    # L·ªçc c√°c k·∫øt qu·∫£ th√†nh c√¥ng
    for method, result in results.items():
        if result.get('success', False) and result.get('text'):
            successful_results[method] = result
    
    if not successful_results:
        return {
            "success": False,
            "error": "Kh√¥ng c√≥ ph∆∞∆°ng ph√°p n√†o th√†nh c√¥ng",
            "text": None,
            "confidence": 0.0,
            "recommended_method": None
        }
    
    # N·∫øu ch·ªâ c√≥ 1 k·∫øt qu·∫£ th√†nh c√¥ng
    if len(successful_results) == 1:
        method, result = list(successful_results.items())[0]
        return {
            "success": True,
            "text": result['text'],
            "confidence": 0.8,  # Confidence cao v√¨ ch·ªâ c√≥ 1 k·∫øt qu·∫£
            "recommended_method": method,
            "single_result": True
        }
    
    # N·∫øu c√≥ nhi·ªÅu k·∫øt qu·∫£ th√†nh c√¥ng - so s√°nh v√† ch·ªçn t·ªët nh·∫•t
    print(f"üìä So s√°nh {len(successful_results)} ph∆∞∆°ng ph√°p th√†nh c√¥ng:")
    
    best_result = None
    best_score = 0
    
    for method, result in successful_results.items():
        score = calculate_result_score(result)
        print(f"   {method}: {score:.2f} ƒëi·ªÉm")
        
        if score > best_score:
            best_score = score
            best_result = result
    
    # Ki·ªÉm tra ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c k·∫øt qu·∫£
    similarity_score = calculate_similarity_score(successful_results)
    
    return {
        "success": True,
        "text": best_result['text'],
        "confidence": min(0.95, best_score / 100),  # Normalize confidence
        "recommended_method": best_result['method'],
        "similarity_score": similarity_score,
        "all_texts": [r['text'] for r in successful_results.values()],
        "single_result": False
    }

def calculate_result_score(result: Dict) -> float:
    """
    T√≠nh ƒëi·ªÉm cho k·∫øt qu·∫£ d·ª±a tr√™n nhi·ªÅu ti√™u ch√≠
    """
    score = 0
    
    # ƒêi·ªÉm c∆° b·∫£n
    score += 50
    
    # ƒêi·ªÉm cho confidence (n·∫øu c√≥)
    if result.get('confidence') is not None:
        if result['confidence'] > 0.8:
            score += 20
        elif result['confidence'] > 0.6:
            score += 15
        elif result['confidence'] > 0.4:
            score += 10
    
    # ƒêi·ªÉm cho processing time (nhanh h∆°n = t·ªët h∆°n)
    if result.get('processing_time'):
        if result['processing_time'] < 2.0:
            score += 15
        elif result['processing_time'] < 5.0:
            score += 10
        elif result['processing_time'] < 10.0:
            score += 5
    
    # ƒêi·ªÉm cho method (Whisper th∆∞·ªùng ch√≠nh x√°c nh·∫•t)
    if "Whisper" in result.get('method', ''):
        score += 10
    elif "Azure" in result.get('method', ''):
        score += 8
    elif "Google" in result.get('method', ''):
        score += 5
    
    return score

def calculate_similarity_score(results: Dict) -> float:
    """
    T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c k·∫øt qu·∫£ text
    """
    texts = [r['text'] for r in results.values()]
    
    if len(texts) < 2:
        return 1.0
    
    # So s√°nh t·ª´ng c·∫∑p text
    total_similarity = 0
    comparisons = 0
    
    for i in range(len(texts)):
        for j in range(i + 1, len(texts)):
            similarity = text_similarity(texts[i], texts[j])
            total_similarity += similarity
            comparisons += 1
    
    return total_similarity / comparisons if comparisons > 0 else 0.0

def text_similarity(text1: str, text2: str) -> float:
    """
    T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa 2 text (ƒë∆°n gi·∫£n)
    """
    # Chu·∫©n h√≥a text
    text1 = text1.lower().strip()
    text2 = text2.lower().strip()
    
    if text1 == text2:
        return 1.0
    
    # T√°ch th√†nh t·ª´
    words1 = set(text1.split())
    words2 = set(text2.split())
    
    if not words1 or not words2:
        return 0.0
    
    # Jaccard similarity
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0.0

def create_summary(results: Dict) -> str:
    """
    T·∫°o t√≥m t·∫Øt k·∫øt qu·∫£
    """
    successful_count = sum(1 for r in results.values() if r.get('success', False))
    total_count = len(results)
    
    summary = f"""
üìã T√ìM T·∫ÆT K·∫æT QU·∫¢:
   ‚Ä¢ T·ªïng ph∆∞∆°ng ph√°p: {total_count}
   ‚Ä¢ Th√†nh c√¥ng: {successful_count}
   ‚Ä¢ T·ª∑ l·ªá th√†nh c√¥ng: {(successful_count/total_count)*100:.1f}%
"""
    
    for method, result in results.items():
        status = "‚úÖ" if result.get('success', False) else "‚ùå"
        text_preview = result.get('text', '')[:50] + "..." if result.get('text') else "N/A"
        summary += f"   ‚Ä¢ {method}: {status} {text_preview}\n"
    
    return summary

# ==============================================================================
# MAIN FUNCTION - TEST STT
# ==============================================================================

def test_speech_to_text(wav_file_path: str, 
                        method: str = "hybrid",
                        azure_key: str = "",
                        azure_region: str = "") -> Dict:
    """
    H√†m ch√≠nh ƒë·ªÉ test Speech-to-Text
    
    Args:
        wav_file_path: ƒê∆∞·ªùng d·∫´n file WAV
        method: "google", "whisper", "azure", "hybrid"
        azure_key: Azure subscription key (n·∫øu d√πng Azure)
        azure_region: Azure region (n·∫øu d√πng Azure)
    
    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ STT
    """
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(wav_file_path):
        return {
            "error": f"File kh√¥ng t·ªìn t·∫°i: {wav_file_path}",
            "success": False
        }
    
    # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
    if not wav_file_path.lower().endswith('.wav'):
        return {
            "error": "File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng .wav",
            "success": False
        }
    
    print(f"üéµ B·∫ÆT ƒê·∫¶U TEST SPEECH-TO-TEXT")
    print(f"üìÅ File: {wav_file_path}")
    print(f"üîß Ph∆∞∆°ng ph√°p: {method}")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        if method == "google":
            result = google_speech_to_text(wav_file_path)
        elif method == "whisper":
            result = whisper_speech_to_text(wav_file_path)
        elif method == "azure":
            if not azure_key or not azure_region:
                return {
                    "error": "C·∫ßn Azure key v√† region ƒë·ªÉ s·ª≠ d·ª•ng Azure Speech",
                    "success": False
                }
            result = azure_speech_to_text(wav_file_path, azure_key, azure_region)
        elif method == "hybrid":
            result = hybrid_speech_to_text(
                wav_file_path,
                use_google=True,
                use_whisper=True,
                use_azure=bool(azure_key and azure_region),
                azure_key=azure_key,
                azure_region=azure_region
            )
        else:
            return {
                "error": f"Ph∆∞∆°ng ph√°p kh√¥ng h·ª£p l·ªá: {method}",
                "success": False
            }
        
        total_time = time.time() - start_time
        
        # Th√™m th√¥ng tin t·ªïng quan
        if isinstance(result, dict) and 'final_result' in result:
            # Hybrid result
            result['total_processing_time'] = total_time
            result['input_file'] = wav_file_path
        else:
            # Single method result
            result['total_processing_time'] = total_time
            result['input_file'] = wav_file_path
        
        print(f"\n‚è±Ô∏è T·ªïng th·ªùi gian x·ª≠ l√Ω: {total_time:.2f}s")
        print("üéâ HO√ÄN TH√ÄNH TEST STT!")
        
        return result
        
    except Exception as e:
        return {
            "error": f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}",
            "success": False,
            "input_file": wav_file_path
        }

# ==============================================================================
# COMMAND LINE INTERFACE
# ==============================================================================

def main():
    """
    Command line interface ƒë·ªÉ test STT
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="Test Speech-to-Text v·ªõi file WAV")
    parser.add_argument("wav_file", help="ƒê∆∞·ªùng d·∫´n file WAV")
    parser.add_argument("--method", choices=["google", "whisper", "azure", "hybrid"], 
                       default="hybrid", help="Ph∆∞∆°ng ph√°p STT")
    parser.add_argument("--azure-key", help="Azure subscription key")
    parser.add_argument("--azure-region", help="Azure region")
    parser.add_argument("--output", help="File output JSON (t√πy ch·ªçn)")
    
    args = parser.parse_args()
    
    # Test STT
    result = test_speech_to_text(
        args.wav_file,
        method=args.method,
        azure_key=args.azure_key or "",
        azure_region=args.azure_region or ""
    )
    
    # In k·∫øt qu·∫£
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {args.output}")
    else:
        print("\nüìÑ K·∫æT QU·∫¢ CHI TI·∫æT:")
        print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    # Test v·ªõi file c·ª• th·ªÉ n·∫øu ch·∫°y tr·ª±c ti·∫øp
    if len(sys.argv) == 1:
        print("üîß TEST MODE - Ch·∫°y tr·ª±c ti·∫øp")
        print("ƒê·ªÉ s·ª≠ d·ª•ng command line:")
        print("python test_stt_audio.py <file_wav> --method <method>")
        print("\nV√≠ d·ª•:")
        print("python test_stt_audio.py audio.wav --method hybrid")
        print("python test_stt_audio.py audio.wav --method whisper")
        print("python test_stt_audio.py audio.wav --method google")
    else:
        main()

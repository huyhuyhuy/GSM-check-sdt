import time
import os
import threading
from typing import Callable
import pyaudio
import wave
import numpy as np
from datetime import datetime
from scipy.signal import correlate

# Professional MFCC imports
try:
    import librosa
    import librosa.feature
    from scipy.signal import butter, filtfilt
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False
    print("‚ö†Ô∏è librosa kh√¥ng c√≥ s·∫µn. C√†i ƒë·∫∑t b·∫±ng: pip install librosa")

try:
    from fastdtw import fastdtw
    from scipy.spatial.distance import euclidean
    DTW_AVAILABLE = True
except ImportError:
    DTW_AVAILABLE = False

# Global audio lock ƒë·ªÉ tr√°nh conflict PyAudio
# _AUDIO_LOCK = threading.Lock()
# _AUDIO_IN_USE = False


def read_wav_file(filename):
    """
    ƒê·ªçc file WAV v√† tr·∫£ v·ªÅ d·ªØ li·ªáu √¢m thanh
    """
    try:
        with wave.open(filename, 'rb') as wf:
            frames = wf.readframes(wf.getnframes())
            audio_data = np.frombuffer(frames, dtype=np.int16)
            
            # N·∫øu l√† stereo, chuy·ªÉn th√†nh mono b·∫±ng c√°ch l·∫•y trung b√¨nh
            if wf.getnchannels() == 2:
                audio_data = audio_data.reshape(-1, 2)
                audio_data = np.mean(audio_data, axis=1)
            
            return audio_data, wf.getframerate()
    except Exception as e:
        print(f"L·ªói ƒë·ªçc file {filename}: {e}")
        return None, None


def resample_and_normalize_audio(audio_data, current_rate, target_rate=44100):
    """
    Resample v√† normalize audio data
    """
    # Convert to mono if stereo
    if len(audio_data.shape) > 1:
        audio_data = np.mean(audio_data, axis=1)
    
    # Simple resampling (linear interpolation)
    if current_rate != target_rate:
        duration = len(audio_data) / current_rate
        new_length = int(duration * target_rate)
        audio_data = np.interp(
            np.linspace(0, len(audio_data), new_length),
            np.arange(len(audio_data)),
            audio_data
        )
    
    # Convert to float and normalize
    audio_data = audio_data.astype(np.float64)
    audio_data = audio_data - np.mean(audio_data)  # Remove DC offset
    
    # Normalize volume
    if np.std(audio_data) > 0:
        audio_data = audio_data / np.std(audio_data)
    
    return audio_data, target_rate


def extract_noise_profile(audio_data, sample_rate, noise_duration=2.0):
    """
    Extract noise profile t·ª´ ƒëo·∫°n ƒë·∫ßu file (ch·ªâ c√≥ "eee...eee")
    """
    noise_samples = int(noise_duration * sample_rate)
    if len(audio_data) < noise_samples:
        noise_samples = len(audio_data) // 2
    
    noise_segment = audio_data[:noise_samples]
    
    # T√≠nh power spectrum c·ªßa noise
    noise_stft = librosa.stft(noise_segment, n_fft=2048, hop_length=512)
    noise_magnitude = np.abs(noise_stft)
    noise_power = noise_magnitude ** 2
    
    # Average power spectrum (noise profile)
    noise_profile = np.mean(noise_power, axis=1)
    
    print(f"   üîß Noise profile extracted t·ª´ {noise_duration}s ƒë·∫ßu ({noise_samples} samples)")
    return noise_profile


def spectral_subtraction(audio_data, noise_profile, sample_rate, alpha=2.0, beta=0.01):
    """
    Spectral subtraction s·ª≠ d·ª•ng noise profile ∆∞·ªõc t√≠nh
    """
    try:
        # STFT of input signal
        stft = librosa.stft(audio_data, n_fft=2048, hop_length=512)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        power = magnitude ** 2
        
        # Expand noise profile to match STFT frames
        noise_power_expanded = noise_profile[:, np.newaxis]
        
        # Spectral subtraction
        clean_power = power - alpha * noise_power_expanded
        
        # Ensure non-negative power v·ªõi floor (beta * original power)
        floor = beta * power
        clean_power = np.maximum(clean_power, floor)
        
        # Reconstruct magnitude v√† combine v·ªõi original phase
        clean_magnitude = np.sqrt(clean_power)
        clean_stft = clean_magnitude * np.exp(1j * phase)
        
        # ISTFT to get clean audio
        clean_audio = librosa.istft(clean_stft, hop_length=512)
        
        print(f"   üîß Spectral subtraction applied (Œ±={alpha}, Œ≤={beta})")
        return clean_audio
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Spectral subtraction failed: {e}")
        return audio_data


def bandpass_filter_speech(audio_data, sample_rate, low_freq=100, high_freq=3800):
    """
    Bandpass filter ƒë·ªÉ ch·ªâ gi·ªØ speech frequency range
    """
    try:
        # Thi·∫øt k·∫ø bandpass filter cho speech (100-3800Hz)
        nyquist = sample_rate / 2
        low = low_freq / nyquist
        high = high_freq / nyquist
        
        # Butterworth bandpass filter
        b, a = butter(4, [low, high], btype='band')
        filtered_audio = filtfilt(b, a, audio_data)
        
        print(f"   üîß Bandpass filter: {low_freq}-{high_freq}Hz (speech range)")
        
        return filtered_audio
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Bandpass filter failed: {e}, s·ª≠ d·ª•ng audio g·ªëc")
        return audio_data


def professional_preprocessing(audio_data, sample_rate, target_sr=16000, 
                              noise_duration=2.0, apply_noise_reduction=True):
    """
    Professional preprocessing pipeline theo ƒë√∫ng chu·∫©n speech processing
    """
    processed_audio = audio_data.copy()
    
    # 1. Resample v·ªÅ 16kHz (optimal cho speech)
    if sample_rate != target_sr:
        processed_audio = librosa.resample(processed_audio, orig_sr=sample_rate, target_sr=target_sr)
        print(f"   üîß Resampled: {sample_rate}Hz ‚Üí {target_sr}Hz")
        sample_rate = target_sr
    
    # 2. Amplitude normalization
    if np.max(np.abs(processed_audio)) > 0:
        processed_audio = processed_audio / np.max(np.abs(processed_audio))
    
    # 3. Pre-emphasis filter (0.97) - quan tr·ªçng cho speech
    processed_audio = librosa.effects.preemphasis(processed_audio, coef=0.97)
    print(f"   üîß Pre-emphasis applied (coef=0.97)")
    
    if apply_noise_reduction:
        # 4. Extract noise profile t·ª´ ƒëo·∫°n ƒë·∫ßu
        noise_profile = extract_noise_profile(processed_audio, sample_rate, noise_duration)
        
        # 5. Spectral subtraction
        processed_audio = spectral_subtraction(processed_audio, noise_profile, sample_rate)
        
        # 6. Bandpass filter 100-3800Hz (optimal cho speech)
        processed_audio = bandpass_filter_speech(processed_audio, sample_rate, 
                                               low_freq=100, high_freq=3800)
    
    return processed_audio, sample_rate


def professional_mfcc_extraction(audio_data, sample_rate, apply_noise_reduction=True):
    """
    Professional MFCC extraction theo chu·∫©n c√¥ng nghi·ªáp
    - 20 MFCC coefficients
    - 25ms frame, 10ms hop
    - Delta + Delta-Delta features  
    - CMVN normalization
    """
    if not LIBROSA_AVAILABLE:
        raise ImportError("librosa is required for professional MFCC extraction")
    
    try:
        # 1. Professional preprocessing
        processed_audio, final_sr = professional_preprocessing(
            audio_data, sample_rate, apply_noise_reduction=apply_noise_reduction
        )
        
        # 2. Optimal MFCC parameters cho speech
        frame_length = int(0.025 * final_sr)  # 25ms frame
        hop_length = int(0.01 * final_sr)     # 10ms hop
        n_mfcc = 20                           # 20 coefficients
        
        print(f"   üìä MFCC params: {n_mfcc} coeffs, {frame_length} frame, {hop_length} hop")
        
        # 3. Extract MFCC features
        mfcc = librosa.feature.mfcc(
            y=processed_audio.astype(np.float32),
            sr=final_sr,
            n_mfcc=n_mfcc,
            n_fft=frame_length * 2,  # Th∆∞·ªùng g·∫•p ƒë√¥i frame length
            hop_length=hop_length,
            window='hamming',
            center=True
        )
        
        # 4. Delta features (t·ªëc ƒë·ªô thay ƒë·ªïi)
        delta_mfcc = librosa.feature.delta(mfcc, order=1)
        
        # 5. Delta-Delta features (gia t·ªëc)
        delta2_mfcc = librosa.feature.delta(mfcc, order=2)
        
        # 6. Combine all features
        all_features = np.vstack([mfcc, delta_mfcc, delta2_mfcc])  # Shape: (60, time_frames)
        
        # 7. CMVN normalization (c·ª±c k·ª≥ quan tr·ªçng cho noise robustness!)
        # Cepstral Mean and Variance Normalization
        mean_norm = np.mean(all_features, axis=1, keepdims=True)
        std_norm = np.std(all_features, axis=1, keepdims=True) + 1e-8  # Tr√°nh division by zero
        
        cmvn_features = (all_features - mean_norm) / std_norm
        
        # 8. Transpose ƒë·ªÉ c√≥ shape (time_frames, feature_dims)
        final_features = cmvn_features.T
        
        print(f"   üìä Professional MFCC shape: {final_features.shape}")
        print(f"       ‚îú‚îÄ MFCC: {n_mfcc} coeffs")
        print(f"       ‚îú‚îÄ Delta: {n_mfcc} coeffs") 
        print(f"       ‚îú‚îÄ Delta¬≤: {n_mfcc} coeffs")
        print(f"       ‚îî‚îÄ CMVN normalized: ‚úÖ")
        
        return final_features
        
    except Exception as e:
        print(f"   ‚ùå Professional MFCC extraction failed: {e}")
        return None


def compute_dtw_distance(mfcc1, mfcc2):
    """
    T√≠nh kho·∫£ng c√°ch DTW gi·ªØa 2 chu·ªói MFCC
    """
    if not DTW_AVAILABLE:
        # Fallback: s·ª≠ d·ª•ng Euclidean distance ƒë∆°n gi·∫£n
        min_len = min(len(mfcc1), len(mfcc2))
        mfcc1_crop = mfcc1[:min_len]
        mfcc2_crop = mfcc2[:min_len]
        
        distances = [euclidean(f1, f2) for f1, f2 in zip(mfcc1_crop, mfcc2_crop)]
        return np.mean(distances)
    
    try:
        # S·ª≠ d·ª•ng FastDTW v·ªõi euclidean distance
        distance, path = fastdtw(mfcc1, mfcc2, dist=euclidean)
        
        # Normalize distance b·ªüi chi·ªÅu d√†i chu·ªói
        normalized_distance = distance / len(path)
        
        return normalized_distance
        
    except Exception as e:
        print(f"L·ªói khi t√≠nh DTW: {e}")
        # Fallback
        min_len = min(len(mfcc1), len(mfcc2))
        mfcc1_crop = mfcc1[:min_len]
        mfcc2_crop = mfcc2[:min_len]
        distances = [euclidean(f1, f2) for f1, f2 in zip(mfcc1_crop, mfcc2_crop)]
        return np.mean(distances)


def mfcc_sliding_window_match(template_3s, check_file_audio, sample_rate, distance_threshold=15.0, use_enhanced=True):
    """
    Tr∆∞·ª£t c·ª≠a s·ªï 3s template (MFCC) qua file check ƒë·ªÉ t√¨m match t·ªët nh·∫•t
    S·ª≠ d·ª•ng Professional MFCC + DTW distance v·ªõi noise reduction
    """
    if not LIBROSA_AVAILABLE:
        print("‚ùå C·∫ßn c√†i ƒë·∫∑t librosa ƒë·ªÉ s·ª≠ d·ª•ng MFCC!")
        return float('inf'), 0
    
    window_size = len(template_3s)  # 3s template
    step_size = sample_rate // 10  # 0.1s step
    
    best_distance = float('inf')
    best_position = 0
    total_comparisons = 0
    valid_comparisons = 0
    
    method_name = "Professional MFCC Pipeline"
    print(f"üéµ {method_name} Sliding Window (3s template)...")
    print(f"   Template length: {len(template_3s)} samples")
    print(f"   Check file length: {len(check_file_audio)} samples")
    print(f"   Distance threshold: {distance_threshold}")
    
    # Extract MFCC cho template
    print(f"   üîß Extracting {method_name} cho template...")
    
    template_mfcc = professional_mfcc_extraction(template_3s, sample_rate, apply_noise_reduction=True)
    
    if template_mfcc is None:
        print("   ‚ùå Kh√¥ng th·ªÉ extract MFCC cho template!")
        return float('inf'), 0
    
    print(f"   üìä Template MFCC shape: {template_mfcc.shape}")
    
    # Scan v·ªõi sliding window
    for i in range(0, len(check_file_audio) - window_size + 1, step_size):
        total_comparisons += 1
        
        # L·∫•y ƒëo·∫°n 3s t·ª´ file check
        check_segment = check_file_audio[i:i+window_size]
        
        # Skip n·∫øu segment qu√° y√™n tƒ©nh
        segment_rms = np.sqrt(np.mean(check_segment**2))
        if segment_rms < 0.1:  # Threshold cho normalized data
            continue
        
        # Extract MFCC cho segment
        check_mfcc = professional_mfcc_extraction(check_segment, sample_rate, apply_noise_reduction=True)
        
        if check_mfcc is None:
            continue
            
        valid_comparisons += 1
        
        # T√≠nh DTW distance
        try:
            dtw_distance = compute_dtw_distance(template_mfcc, check_mfcc)
            
            if dtw_distance < best_distance:
                best_distance = dtw_distance
                best_position = i / sample_rate
                
                if dtw_distance < distance_threshold * 1.5:  # Show progress
                    print(f"   üìà Good match: DTW={dtw_distance:.2f} at {best_position:.1f}s")
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error at position {i/sample_rate:.1f}s: {e}")
            continue
    
    print(f"   ‚úÖ Scan complete. Best DTW distance: {best_distance:.2f} at {best_position:.1f}s")
    print(f"   üìä Stats: {total_comparisons} total, {valid_comparisons} valid")
    
    return best_distance, best_position


def parse_clcc_status(clcc_response: str) -> int:
    """Parse status t·ª´ response AT+CLCC"""
    try:
        lines = clcc_response.split('\n')
        for line in lines:
            if '+CLCC:' in line:
                parts = line.strip().split(',')
                if len(parts) >= 3:
                    status = int(parts[2])
                    return status
        return -1
    except Exception:
        return -1


# ==============================================================================
# LOGIC C≈® - ƒê√É COMMENT
# Thu·∫≠t to√°n song song GSM + ESP32 ph·ª©c t·∫°p, thay th·∫ø b·∫±ng audio analysis ƒë∆°n gi·∫£n
# ==============================================================================
def viettel_combined_check_OLD(device, phone_number: str, log_callback: Callable = None) -> str:
    """
    [COMMENTED OUT - LOGIC C≈®]
    Ch·∫°y song song 2 lu·ªìng:
    - GSM (K·∫æT QU·∫¢ 1): t√¨m HO·∫†T ƒê·ªòNG d·ª±a v√†o CLCC 0/3, +COLP:, BUSY/RING/RINGING/CONNECT.
    - ESP (K·∫æT QU·∫¢ 2): ch·ªù 2s sau ATD r·ªìi thu 12s ADC k√™nh 1,2; ph√¢n t√≠ch v√πng d√†y ƒë·∫∑c.

    Quy t·∫Øc quy·∫øt ƒë·ªãnh cu·ªëi:
    - N·∫øu K·∫æT QU·∫¢ 1 = HO·∫†T ƒê·ªòNG ‚Üí k·∫øt qu·∫£ cu·ªëi = HO·∫†T ƒê·ªòNG (nh∆∞ng v·∫´i ƒë·ª£i ESP xong ƒë·ªÉ an to√†n).
    - Ng∆∞·ª£c l·∫°i ‚Üí k·∫øt qu·∫£ cu·ªëi theo K·∫æT QU·∫¢ 2.
    
    THAY TH·∫æ B·∫∞NG: viettel_audio_check() - s·ª≠ d·ª•ng template matching
    """

    """
    # COMMENTED OUT - TO√ÄN B·ªò LOGIC C≈®
    def log(message: str):
        if log_callback:
            log_callback(message)
        else:
            print(f"[{phone_number}] {message}")

    try:
        # ƒê·∫£m b·∫£o modem s·∫µn s√†ng
        ready_response = device.send_command_quick("AT")
        if "OK" not in ready_response:
            log("Modem kh√¥ng s·∫µn s√†ng")
            try:
                device.send_command_quick("ATH")
            except Exception:
                pass
            return "THU√ä BAO"

        device.send_command_quick("ATH")
        time.sleep(1)

        # G·ª≠i l·ªánh g·ªçi
        call_command = f"ATD{phone_number};"
        log("G·ª≠i l·ªánh g·ªçi...")
        device.serial_connection.reset_input_buffer()
        device.serial_connection.reset_output_buffer()
        device.serial_connection.write((call_command + "\r\n").encode())
        time.sleep(1)  # Ch·ªù 1s ƒë·ªÉ cu·ªôc g·ªçi ·ªïn ƒë·ªãnh

        # B·∫Øt ƒë·∫ßu 2 lu·ªìng song song
        # log("B·∫Øt ƒë·∫ßu GSM v√† ESP threads...")

        gsm_done = threading.Event()
        esp_done = threading.Event()
        gsm_result = {}
        esp_result = {}

        # GSM thread: x√°c ƒë·ªãnh K·∫æT QU·∫¢ 1
        def gsm_thread_func():
            try:
                start_time = time.time()
                timeout = 15.0

                clcc_statuses = []
                gsm_responses = []
                active_detected = False
                ath_sent_immediately = False

                while time.time() - start_time < timeout and not gsm_done.is_set():
                    clcc_response = device.send_command_quick("AT+CLCC", 0.5)
                    if "+CLCC:" in clcc_response:
                        status = parse_clcc_status(clcc_response)
                        clcc_statuses.append(status)
                        log(f"ESP Status: {status}")
                        if status in [0, 3]:
                            active_detected = True
                            gsm_result['final'] = 'HO·∫†T ƒê·ªòNG'
                            # N·∫øu status==0 (ƒë√£ nh·∫•c m√°y) ‚Üí c√∫p ngay ƒë·ªÉ tr√°nh t·ªën ph√≠
                            if status == 0 and not ath_sent_immediately:
                                try:
                                    device.send_command_quick("ATH")
                                    ath_sent_immediately = True
                                    # log("GSM Thread - Ph√°t hi·ªán CLCC=0 ‚Üí g·ª≠i ATH ngay")
                                except Exception:
                                    pass
                            # log("GSM Thread - K·∫æT QU·∫¢ 1 = HO·∫†T ƒê·ªòNG")
                            gsm_done.set()
                            return

                    try:
                        time.sleep(0.5)
                        if device.serial_connection.in_waiting > 0:
                            chunk = device.serial_connection.read(device.serial_connection.in_waiting).decode('utf-8', errors='ignore')
                            if chunk.strip():
                                gsm_responses.append(chunk)
                                log(f"GSM Thread - Response: '{chunk.strip()}'")
                                up = chunk.upper()
                                if ("+COLP:" in up or "BUSY" in up or "RINGING" in up or
                                    "RING" in up or "CONNECT" in up):
                                    active_detected = True
                                    gsm_result['final'] = 'HO·∫†T ƒê·ªòNG'
                                    # N·∫øu l√† COLP/CONNECT (ƒë√£ nh·∫•c m√°y) ‚Üí c√∫p ngay ƒë·ªÉ tr√°nh t·ªën ph√≠
                                    if (("+COLP:" in up or "CONNECT" in up) and not ath_sent_immediately):
                                        try:
                                            device.send_command_quick("ATH")
                                            ath_sent_immediately = True
                                            # log("GSM Thread - Ph√°t hi·ªán COLP/CONNECT ‚Üí g·ª≠i ATH ngay")
                                        except Exception:
                                            pass
                                    # log("GSM Thread - K·∫æT QU·∫¢ 1 = HO·∫†T ƒê·ªòNG (keyword)")
                                    gsm_done.set()
                                    return
                        else:
                            if time.time() - start_time > 5.0:
                                # log(f"GSM Thread - Debug: in_waiting={device.serial_connection.in_waiting}")
                                try:
                                    device.serial_connection.timeout = 0.1
                                    test_read = device.serial_connection.read(100)
                                    if test_read:
                                        test_text = test_read.decode('utf-8', errors='ignore')
                                        # log(f"GSM Thread - Debug: Found data: '{test_text.strip()}'")
                                        gsm_responses.append(test_text)
                                    device.serial_connection.timeout = device.timeout
                                except Exception as e:
                                    log(f"GSM Thread - Debug read e: {str(e)}")
                    except Exception as e:
                        log(f"GSM Thread - L·ªói ƒë·ªçc response: {str(e)}")

                gsm_text = " ".join(gsm_responses).upper()
                gsm_result['clcc_statuses'] = clcc_statuses
                gsm_result['gsm_text'] = gsm_text
                if not active_detected:
                    unique_status = set(clcc_statuses)
                    if unique_status and unique_status.issubset({2, 6}):
                        gsm_result['final'] = 'THU√ä BAO'
                        # log("GSM Thread - K·∫æT QU·∫¢ 1 = THU√ä BAO (ch·ªâ 2/6)")
                    else:
                        gsm_result['final'] = 'THU√ä BAO'
                log(f"GSM Thread - Total responses: {len(gsm_responses)}")
                if gsm_responses:
                    log(f"GSM Thread - Last response: '{gsm_responses[-1].strip()}'")
            except Exception as e:
                log(f"GSM Thread - L·ªói: {str(e)}")
                gsm_result['error'] = str(e)
            finally:
                gsm_done.set()

        # ESP thread: thu 12s ADC k√™nh 1,2 sau khi ch·ªù 2s
        def esp_thread_func():
            try:
                if device.audio_analyzer:
                    log(f"ESP Thread - Thu ADC, l∆∞u file v√† ph√¢n t√≠ch")
                    timestamp_str = time.strftime("%H_%M_%S")
                    output_dir = "adc_logs"
                    os.makedirs(output_dir, exist_ok=True)

                    # log("ESP Thread - Ch·ªù 2s sau ATD tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu thu ADC...")
                    time.sleep(2.0)

                    samples_map = device.audio_analyzer.collect_adc_samples_multi_channel([1, 2], duration=12.0)

                    # for ch, samples in samples_map.items():
                    #     try:
                    #         file_path = os.path.join(output_dir, f"ADC_channel{ch}_{timestamp_str}.txt")
                    #         with open(file_path, 'w', encoding='utf-8') as f:
                    #             for val in samples:
                    #                 f.write(f"{val}\n")
                    #         log(f"ESP Thread - ƒê√£ l∆∞u {len(samples)} m·∫´u: {file_path}")
                    #     except Exception as e:
                    #         log(f"ESP Thread - L·ªói l∆∞u file channel {ch}: {str(e)}")

                    device_channel = getattr(device, 'audio_channel', 1)
                    if device_channel not in [1, 2]:
                        device_channel = 1
                    device_samples = samples_map.get(device_channel, [])
                    if device_samples:
                        analysis = device.audio_analyzer._find_rectangular_regions(device_samples)
                        pattern = analysis.get('pattern', 'SILENCE')
                    else:
                        pattern = 'SILENCE'
                    esp_result['pattern'] = pattern
                    # log(f"ESP Thread - Pattern (channel {device_channel}): {pattern}")
                else:
                    # log("ESP Thread - Kh√¥ng c√≥ audio analyzer")
                    esp_result['pattern'] = 'SILENCE'
            except Exception as e:
                log(f"ESP Thread - L·ªói: {str(e)}")
                esp_result['pattern'] = 'SILENCE'
            finally:
                esp_done.set()

        # Kh·ªüi ƒë·ªông threads
        gsm_thread = threading.Thread(target=gsm_thread_func)
        esp_thread = threading.Thread(target=esp_thread_func)
        gsm_thread.start()
        esp_thread.start()

        # Ch·ªù GSM xong ƒë·ªÉ l·∫•y K·∫æT QU·∫¢ 1, nh∆∞ng KH√îNG tr·∫£ v·ªÅ s·ªõm
        gsm_thread.join(timeout=15.0)
        gsm_final = gsm_result.get('final', 'THU√ä BAO')
        # log(f"K·∫æT QU·∫¢ 1 (GSM): {gsm_final}")

        # Lu√¥n ch·ªù ESP ho√†n th√†nh ƒë·ªÉ tr√°nh xung ƒë·ªôt l·ªánh ·ªü l·∫ßn g·ªçi ti·∫øp theo
        esp_thread.join(timeout=15.0)
        pattern = esp_result.get('pattern', 'SILENCE')
        # log(f"K·∫æT QU·∫¢ 2 (ESP): {pattern}")

        # Quy t·∫Øc quy·∫øt ƒë·ªãnh cu·ªëi c√πng
        if gsm_final == 'HO·∫†T ƒê·ªòNG':
            final_result = 'HO·∫†T ƒê·ªòNG'
        else:
            if pattern == 'RINGTONE':
                final_result = 'HO·∫†T ƒê·ªòNG'
            elif pattern == 'BLOCKED':
                final_result = 'S·ªê KH√îNG ƒê√öNG'
            else:
                final_result = 'THU√ä BAO'

        # D·ª´ng cu·ªôc g·ªçi
        device.send_command_quick("ATH")
        time.sleep(1)
        return final_result

    except Exception as e:
        log(f"L·ªói check Viettel: {str(e)}")
        try:
            device.send_command_quick("ATH")
        except Exception:
            pass
        return "THU√ä BAO"
    """
    # K·∫æT TH√öC COMMENT - LOGIC C≈® ƒê√É ƒê∆Ø·ª¢C COMMENT TO√ÄN B·ªò
    pass  # Placeholder cho function c≈©


def viettel_combined_check(device, phone_number: str, log_callback: Callable = None) -> str:
    """
    LOGIC M·ªöI - ƒê∆°n gi·∫£n h√≥a cho s·ªë Viettel:
    1. GSM g·ª≠i l·ªánh g·ªçi (ATD)
    2. Thu √¢m audio v√† ph√¢n t√≠ch b·∫±ng template matching
    3. Tr·∫£ v·ªÅ: SO KHONG DUNG, THUE BAO, ho·∫∑c HOAT DONG
    
    Ch·ªâ d√†nh cho c·ªïng COM38 (c·ªïng c·ªë ƒë·ªãnh x·ª≠ l√Ω Viettel)
    """
    return viettel_audio_check(device, phone_number, log_callback)


def analyze_audio_with_templates(wave_filename: str, log_callback: Callable) -> str:
    """
    Ph√¢n t√≠ch audio file v·ªõi Professional MFCC + DTW (Option 7 style)
    Ch·ªâ s·ª≠ d·ª•ng 2 templates ch√≠nh: THUE BAO v√† SO KHONG DUNG
    Tr·∫£ v·ªÅ: SO KHONG DUNG, THUE BAO, ho·∫∑c HOAT DONG
    """
    if not LIBROSA_AVAILABLE:
        if log_callback:
            log_callback("‚ùå C·∫ßn c√†i ƒë·∫∑t librosa ƒë·ªÉ s·ª≠ d·ª•ng Professional MFCC!")
        return "HOAT DONG"
    
    # Ch·ªâ check 2 templates ch√≠nh (nh∆∞ Option 7)
    templates = {
        "THUE BAO": "template_thue_bao_ok.wav",
        "SO KHONG DUNG": "template_so_khong_dung_ok.wav"
    }
    
    def log(message: str):
        if log_callback:
            log_callback(message)
    
    try:
        log("üéµ PROFESSIONAL MFCC + DTW ANALYSIS")
        log("üîß Professional Pipeline: 16kHz+Pre-emphasis+Noise profile+CMVN")
        
        # ƒê·ªçc file c·∫ßn check
        check_audio, check_rate = read_wav_file(wave_filename)
        if check_audio is None:
            log(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file: {wave_filename}")
            return "HOAT DONG"
        
        log(f"üìÇ File check: {len(check_audio)} samples, {check_rate}Hz")
        
        # Chu·∫©n b·ªã file check
        check_audio_norm, target_rate = resample_and_normalize_audio(check_audio, check_rate)
        log(f"   Sau normalize: {len(check_audio_norm)} samples, {target_rate}Hz")
        
        results = {}
        
        # Ki·ªÉm tra t·ª´ng template 
        for template_name, template_file in templates.items():
            if not os.path.exists(template_file):
                log(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y: {template_file}")
                continue
                
            log(f"üéµ KI·ªÇM TRA TEMPLATE: {template_name}")
            
            # ƒê·ªçc template
            template_audio, template_rate = read_wav_file(template_file)
            if template_audio is None:
                log(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc template: {template_file}")
                continue
            
            # Chu·∫©n b·ªã template (resample + normalize)
            template_norm, _ = resample_and_normalize_audio(template_audio, template_rate, target_rate)
            
            # L·∫•y 3s ƒë·∫ßu template
            window_3s = target_rate * 3
            template_3s = template_norm[:min(window_3s, len(template_norm))]
            
            actual_duration = len(template_3s) / target_rate
            log(f"   ‚úÇÔ∏è S·ª≠ d·ª•ng {actual_duration:.1f}s ƒë·∫ßu template ({len(template_3s)} samples)")
            
            # MFCC sliding window match
            distance, position = mfcc_sliding_window_match(
                template_3s, check_audio_norm, target_rate, distance_threshold=15.0
            )
            
            # Convert distance to similarity score v·ªõi adaptive scaling
            if distance == float('inf'):
                similarity_score = 0.0
            else:
                # Adaptive scaling d·ª±a tr√™n enhanced features (gi·ªëng Option 7)
                if distance < 8.0:      # Excellent match
                    similarity_score = 0.95 + (8.0 - distance) * 0.005  # 0.95-1.0
                elif distance < 15.0:   # Good match  
                    similarity_score = 0.8 + (15.0 - distance) * 0.015 / 7.0  # 0.8-0.95
                elif distance < 25.0:   # Fair match
                    similarity_score = 0.5 + (25.0 - distance) * 0.3 / 10.0   # 0.5-0.8
                else:                   # Poor match
                    similarity_score = max(0, 0.5 - (distance - 25.0) * 0.02)  # 0-0.5
            
            results[template_name] = {
                'distance': distance,
                'similarity': similarity_score,
                'position': position,
            }
            
            log(f"   üéØ K·∫øt qu·∫£: DTW distance={distance:.2f}, similarity={similarity_score:.3f} (t·∫°i {position:.1f}s)")
        
        # T·ªïng k·∫øt k·∫øt qu·∫£ (gi·ªëng Option 7)
        if not results:
            log("‚ùå Kh√¥ng c√≥ template n√†o ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng")
            return "HOAT DONG"
        
        # S·∫Øp x·∫øp theo distance (th·∫•p nh·∫•t = t·ªët nh·∫•t)
        sorted_results = sorted(results.items(), key=lambda x: x[1]['distance'])
        
        for i, (name, data) in enumerate(sorted_results):
            icon = "ü•á" if i == 0 else "ü•à"
            distance = data['distance']
            similarity = data['similarity']
            if distance == float('inf'):
                log(f"{icon} {name}: DTW=‚àû (kh√¥ng t√≠nh ƒë∆∞·ª£c)")
            else:
                log(f"{icon} {name}: DTW={distance:.2f} Sim={similarity:.3f} (t·∫°i {data['position']:.1f}s)")
        
        # X√°c ƒë·ªãnh k·∫øt qu·∫£ cu·ªëi c√πng (Logic Option 7)
        best_template, best_data = sorted_results[0]
        best_distance = best_data['distance']
        
        # DTW threshold v√† logic nh∆∞ Option 7
        dtw_threshold = 9.3
        
        if best_distance == float('inf'):
            log(f"‚ùå KH√îNG TH·ªÇ T√çNH TO√ÅN - L·ªói MFCC extraction")
            final_result = "HOAT DONG"
        elif best_distance <= dtw_threshold:
            log(f"‚úÖ K·∫æT QU·∫¢ TIN C·∫¨Y (DTW ‚â§ {dtw_threshold})")
            final_result = best_template
        else:
            log(f"‚ö†Ô∏è DTW > {dtw_threshold} ‚Üí PH√ÇN LO·∫†I L√Ä HO·∫†T ƒê·ªòNG")
            final_result = "HOAT DONG"
        
        log(f"üéØ K·∫æT QU·∫¢ CU·ªêI C√ôNG: {final_result}")
        return final_result
            
    except Exception as e:
        log(f"L·ªói ph√¢n t√≠ch audio: {str(e)}")
        return "HOAT DONG"


def viettel_audio_check(device, phone_number: str, log_callback: Callable = None) -> str:
    """
    Check s·ªë Viettel b·∫±ng c√°ch:
    1. G·ª≠i l·ªánh g·ªçi ATD
    2. Monitor GSM response song song v·ªõi thu √¢m
    3. D·ª´ng s·ªõm n·∫øu CLCC=0 ho·∫∑c +COLP (ng∆∞·ªùi nh·∫•c m√°y) ‚Üí HO·∫†T ƒê·ªòNG
    4. N·∫øu kh√¥ng, ph√¢n t√≠ch audio v·ªõi templates
    5. Lu√¥n g·ª≠i ATH ƒë·ªÉ ti·∫øt ki·ªám ph√≠
    
    CRITICAL: Ch·ªâ 1 s·ªë Viettel ƒë∆∞·ª£c x·ª≠ l√Ω t·∫°i 1 th·ªùi ƒëi·ªÉm ƒë·ªÉ tr√°nh PyAudio conflict
    """
    # Imports ƒë√£ ƒë∆∞·ª£c ƒë∆∞a l√™n ƒë·∫ßu file
    
    def log(message: str):
        if log_callback:
            log_callback(message)
        else:
            print(f"[{phone_number}] {message}")
    
    try:
        # ƒê·∫£m b·∫£o modem s·∫µn s√†ng
        ready_response = device.send_command_quick("AT")
        if "OK" not in ready_response:
            log("Modem kh√¥ng s·∫µn s√†ng")
            return "THUE BAO"
        
        # Cleanup tr∆∞·ªõc khi g·ªçi
        device.send_command_quick("ATH")
        time.sleep(1)
        
        # B·∫Øt ƒë·∫ßu cu·ªôc g·ªçi
        call_command = f"ATD{phone_number};"
        log(f"B·∫Øt ƒë·∫ßu g·ªçi {phone_number}...")
        device.serial_connection.reset_input_buffer()
        device.serial_connection.reset_output_buffer()
        device.serial_connection.write((call_command + "\r\n").encode())
        
        # Ch·ªù 1 gi√¢y ƒë·ªÉ cu·ªôc g·ªçi kh·ªüi t·∫°o
        time.sleep(1)
        
        # S·ª≠ d·ª•ng dual-threading v·ªõi kh·∫£ nƒÉng d·ª´ng s·ªõm
        log("B·∫Øt ƒë·∫ßu dual-threading: GSM monitoring + Audio recording...")
        result = gsm_monitor_with_audio_recording(device, phone_number, log)
        
        # Lu√¥n d·ª´ng cu·ªôc g·ªçi
        try:
            device.send_command_quick("ATH")
            time.sleep(0.5)
        except:
            pass
        
        return result
            
    except Exception as e:
        log(f"L·ªói check Viettel: {str(e)}")
        try:
            device.send_command_quick("ATH")
            time.sleep(0.5)
        except:
            pass
        return "THU√ä BAO"


def gsm_monitor_with_audio_recording(device, phone_number: str, log_callback: Callable) -> str:
    """
    Ch·∫°y song song 2 lu·ªìng:
    1. GSM Thread: Monitor CLCC status v√† response ‚Üí D·ª´ng s·ªõm n·∫øu c√≥ ng∆∞·ªùi nh·∫•c m√°y
    2. Audio Thread: Thu √¢m v√† ph√¢n t√≠ch templates (B·ªé LOCK - thu √¢m tr·ª±c ti·∫øp)
    
    ∆Øu ti√™n: GSM detection ‚Üí Early stop ‚Üí Audio analysis ‚Üí Fallback
    """
    import threading
    
    def log(message: str):
        if log_callback:
            log_callback(message)
    
    # Shared variables
    gsm_done = threading.Event()
    audio_done = threading.Event()
    should_stop_audio = threading.Event()  # Signal ƒë·ªÉ d·ª´ng audio s·ªõm
    
    gsm_result = {'status': None, 'early_stop': False}
    audio_result = {'pattern': None}
    
    def gsm_monitoring_thread():
        """
        Monitor GSM responses trong 20 gi√¢y
        D·ª´ng s·ªõm n·∫øu ph√°t hi·ªán CLCC=0 ho·∫∑c +COLP (ng∆∞·ªùi nh·∫•c m√°y)
        ‚Üí Signal audio thread d·ª´ng v√† tr·∫£ v·ªÅ HO·∫†T ƒê·ªòNG ngay l·∫≠p t·ª©c
        """
        try:
            start_time = time.time()
            timeout = 20.0  # T·ªëi ƒëa 20 gi√¢y
            
            while time.time() - start_time < timeout and not gsm_done.is_set():
                # Check CLCC status
                clcc_response = device.send_command_quick("AT+CLCC", 0.3)
                if "+CLCC:" in clcc_response:
                    status = parse_clcc_status(clcc_response)
                    if status == 0:  # Ng∆∞·ªùi nh·∫•c m√°y
                        log(f"üéØ CLCC=0 - Ng∆∞·ªùi nh·∫•c m√°y! ‚Üí HO·∫†T ƒê·ªòNG")
                        gsm_result['status'] = 'HO·∫†T ƒê·ªòNG'
                        gsm_result['early_stop'] = True
                        # D·ª´ng cu·ªôc g·ªçi ngay
                        device.send_command_quick("ATH")
                        # Signal audio thread d·ª´ng
                        should_stop_audio.set()
                        gsm_done.set()
                        return
                
                # Check serial response
                try:
                    if device.serial_connection.in_waiting > 0:
                        chunk = device.serial_connection.read(device.serial_connection.in_waiting).decode('utf-8', errors='ignore')
                        if chunk.strip():
                            chunk_upper = chunk.upper()
                            log(f"GSM Response: '{chunk.strip()}'")
                            
                            # Check for +COLP (ng∆∞·ªùi nh·∫•c m√°y)
                            if "+COLP:" in chunk_upper:
                                log(f"üéØ +COLP detected - Ng∆∞·ªùi nh·∫•c m√°y! ‚Üí HO·∫†T ƒê·ªòNG")
                                gsm_result['status'] = 'HO·∫†T ƒê·ªòNG'
                                gsm_result['early_stop'] = True
                                # D·ª´ng cu·ªôc g·ªçi ngay
                                device.send_command_quick("ATH")
                                # Signal audio thread d·ª´ng
                                should_stop_audio.set()
                                gsm_done.set()
                                return
                            
                            # Check for other activity indicators
                            if any(keyword in chunk_upper for keyword in ["CONNECT", "BUSY", "RINGING"]):
                                log(f"GSM Activity: {chunk.strip()}")
                                # Kh√¥ng d·ª´ng s·ªõm, ƒë·ªÉ audio analysis quy·∫øt ƒë·ªãnh
                
                except Exception as e:
                    log(f"GSM monitoring error: {str(e)}")
                
                time.sleep(0.5)  # Check m·ªói 0.5 gi√¢y
            
            log("GSM monitoring ho√†n th√†nh (timeout)")
            gsm_done.set()
            
        except Exception as e:
            log(f"GSM monitoring thread error: {str(e)}")
            gsm_done.set()
    
    def audio_recording_thread():
        """
        Thu √¢m v√† ph√¢n t√≠ch audio templates
        C√≥ th·ªÉ b·ªã d·ª´ng s·ªõm b·ªüi GSM thread khi ph√°t hi·ªán ng∆∞·ªùi nh·∫•c m√°y
        B·ªé LOCK - thu √¢m tr·ª±c ti·∫øp
        """
        # B·ªè lock - thu √¢m tr·ª±c ti·∫øp
        log("B·∫Øt ƒë·∫ßu thu √¢m...")
        
        # Thi·∫øt l·∫≠p thu √¢m
        CHUNK = 1024
        FORMAT = pyaudio.paInt16  
        CHANNELS = 2
        RATE = 44100
        RECORD_SECONDS = 20
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        wave_filename = f"viettel_audio_{phone_number}_{timestamp}.wav"
        
        p = pyaudio.PyAudio()
        
        # Ki·ªÉm tra audio device c√≥ s·∫µn kh√¥ng
        if p.get_device_count() == 0:
            log("Kh√¥ng t√¨m th·∫•y audio device!")
            p.terminate()
            audio_result['pattern'] = 'NO_AUDIO_DEVICE'
            audio_done.set()
            return
        
        try:
            stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                           input=True, frames_per_buffer=CHUNK)
        except Exception as audio_error:
            log(f"L·ªói m·ªü audio stream: {str(audio_error)}")
            p.terminate()
            audio_result['pattern'] = 'NO_AUDIO_DEVICE'
            audio_done.set()
            return
        
        frames = []
        total_chunks = int(RATE / CHUNK * RECORD_SECONDS)
        
        for i in range(total_chunks):
            # Check n·∫øu GSM thread y√™u c·∫ßu d·ª´ng
            if should_stop_audio.is_set():
                log("Audio recording d·ª´ng s·ªõm (GSM detected)")
                break
            
            try:
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames.append(data)
            except Exception as read_error:
                log(f"L·ªói ƒë·ªçc audio chunk {i}: {str(read_error)}")
                # Ti·∫øp t·ª•c thay v√¨ crash
                continue
            
            # Log progress m·ªói 2 gi√¢y
            if i % (int(RATE / CHUNK * 2)) == 0:
                elapsed = i // int(RATE / CHUNK)
                log(f"Thu √¢m: {elapsed}s/{RECORD_SECONDS}s")
        
        # Cleanup audio stream safely
        try:
            stream.stop_stream()
            stream.close()
        except Exception as cleanup_error:
            log(f"L·ªói cleanup audio stream: {str(cleanup_error)}")
        
        # N·∫øu b·ªã d·ª´ng s·ªõm, v·∫´n l∆∞u file ƒë·ªÉ ki·ªÉm tra
        if should_stop_audio.is_set():
            if frames:  # C√≥ data thu ƒë∆∞·ª£c
                try:
                    log("L∆∞u audio d·ª´ng s·ªõm...")
                    wf = wave.open(wave_filename, 'wb')
                    wf.setnchannels(CHANNELS)
                    wf.setsampwidth(p.get_sample_size(FORMAT))
                    wf.setframerate(RATE)
                    wf.writeframes(b''.join(frames))
                    wf.close()
                    log(f"üíæ ƒê√£ l∆∞u audio (early stop): {wave_filename}")
                except Exception as early_save_error:
                    log(f"L·ªói l∆∞u audio early stop: {str(early_save_error)}")
            
            p.terminate()
            audio_result['pattern'] = 'EARLY_STOP'
            audio_done.set()
            return
        
        # L∆∞u v√† ph√¢n t√≠ch audio
        if frames:
            try:
                log("L∆∞u v√† ph√¢n t√≠ch audio...")
                wf = wave.open(wave_filename, 'wb')
                wf.setnchannels(CHANNELS)
                wf.setsampwidth(p.get_sample_size(FORMAT))
                wf.setframerate(RATE)
                wf.writeframes(b''.join(frames))
                wf.close()
                
                # Ph√¢n t√≠ch templates
                pattern = analyze_audio_with_templates(wave_filename, log)
                audio_result['pattern'] = pattern
                
                # L∆∞u file ƒë·ªÉ user ki·ªÉm tra
                log(f"üíæ ƒê√£ l∆∞u audio: {wave_filename}")
                
            except Exception as file_error:
                log(f"L·ªói l∆∞u/ph√¢n t√≠ch audio: {str(file_error)}")
                audio_result['pattern'] = 'FILE_ERROR'
            
            # GI·ªÆ L·∫†I FILE ƒë·ªÉ user ki·ªÉm tra (kh√¥ng x√≥a n·ªØa)
            # try:
            #     if os.path.exists(wave_filename):
            #         os.remove(wave_filename)
            # except Exception as delete_error:
            #     log(f"L·ªói x√≥a file t·∫°m: {str(delete_error)}")
        else:
            audio_result['pattern'] = 'NO_AUDIO'
        
        p.terminate()
        log("Audio recording ho√†n th√†nh")
        audio_done.set()
        
        # Kh√¥ng c·∫ßn cleanup lock n·ªØa
    
    # Kh·ªüi ƒë·ªông 2 threads
    gsm_thread = threading.Thread(target=gsm_monitoring_thread)
    audio_thread = threading.Thread(target=audio_recording_thread)
    
    gsm_thread.start()
    audio_thread.start()
    
    # Ch·ªù c·∫£ 2 threads ho√†n th√†nh (timeout 25s)
    gsm_thread.join(timeout=25)
    audio_thread.join(timeout=25)
    
    # Quy·∫øt ƒë·ªãnh k·∫øt qu·∫£ cu·ªëi c√πng
    if gsm_result.get('early_stop', False):
        # GSM ƒë√£ ph√°t hi·ªán ng∆∞·ªùi nh·∫•c m√°y ‚Üí ∆Øu ti√™n cao nh·∫•t
        log(f"üéØ K·∫øt qu·∫£: {gsm_result['status']} (Early detection)")
        return gsm_result['status']
    
    # Fallback theo audio analysis
    pattern = audio_result.get('pattern', 'ERROR')
    
    if pattern == 'SO KHONG DUNG':
        return "S·ªê KH√îNG ƒê√öNG"
    elif pattern == 'THUE BAO':
        return "THU√ä BAO"
    elif pattern in ['DE LAI LOI NHAN', 'HOAT DONG', 'EARLY_STOP', 'NO_AUDIO']:
        return "HO·∫†T ƒê·ªòNG"  # ƒê√≠nh ch√≠nh: "ƒë·ªÉ l·∫°i l·ªùi nh·∫Øn" ‚Üí HO·∫†T ƒê·ªòNG
    elif pattern in ['NO_AUDIO_DEVICE', 'AUDIO_ERROR', 'FILE_ERROR', 'AUDIO_BUSY', 'AUDIO_TIMEOUT']:
        log(f"Audio l·ªói ({pattern}) ‚Üí Fallback HO·∫†T ƒê·ªòNG")
        return "HO·∫†T ƒê·ªòNG"  # Fallback khi audio b·ªã l·ªói ho·∫∑c busy
    else:
        return "THU√ä BAO"  # Default fallback


def analyze_audio_with_templates(wave_filename: str, log_callback: Callable) -> str:
    """
    Ph√¢n t√≠ch audio file v·ªõi 3 templates
    Tr·∫£ v·ªÅ: SO KHONG DUNG, THUE BAO, DE LAI LOI NHAN, ho·∫∑c HOAT DONG
    """
    templates = {
        "SO KHONG DUNG": "template_so_khong_dung_ok.wav",
        "THUE BAO": "template_thue_bao_ok.wav",
        "DE LAI LOI NHAN": "template_de_lai_loi_nhan_ok.wav"
    }
    
    def log(message: str):
        if log_callback:
            log_callback(message)
    
    try:
        results = {}
        
        for label, template_file in templates.items():
            if not os.path.exists(template_file):
                log(f"Kh√¥ng t√¨m th·∫•y template: {template_file}")
                continue
            
            # So s√°nh b·∫±ng correlation
            is_match = compare_audio_files_simple(template_file, wave_filename, threshold=0.3)
            results[label] = is_match
            
            if is_match:
                log(f"‚úÖ Kh·ªõp v·ªõi template: {label}")
        
        # Logic ph√¢n lo·∫°i
        matched_templates = [label for label, is_match in results.items() if is_match]
        
        if len(matched_templates) == 0:
            return "HOAT DONG"  # Kh√¥ng kh·ªõp template n√†o
        elif "SO KHONG DUNG" in matched_templates:
            return "SO KHONG DUNG"  # ∆Øu ti√™n cao nh·∫•t
        elif "THUE BAO" in matched_templates:
            return "THUE BAO"
        elif "DE LAI LOI NHAN" in matched_templates:
            return "HOAT DONG"  # ƒê√≠nh ch√≠nh: "ƒë·ªÉ l·∫°i l·ªùi nh·∫Øn" ‚Üí HO·∫†T ƒê·ªòNG
        else:
            return "HOAT DONG"  # Fallback
            
    except Exception as e:
        log(f"L·ªói ph√¢n t√≠ch audio: {str(e)}")
        return "HOAT DONG"


def record_and_analyze_audio(phone_number: str, log_callback: Callable) -> str:
    """
    Thu √¢m v√† ph√¢n t√≠ch v·ªõi Professional MFCC + DTW (Option 7)
    Tr·∫£ v·ªÅ: SO KHONG DUNG, THUE BAO, ho·∫∑c HOAT DONG
    """
    def log(message: str):
        if log_callback:
            log_callback(message)
    
    try:
        # Thi·∫øt l·∫≠p thu √¢m
        CHUNK = 1024
        FORMAT = pyaudio.paInt16  
        CHANNELS = 2
        RATE = 44100
        RECORD_SECONDS = 20
        
        # T·∫°o t√™n file v·ªõi timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        wave_filename = f"viettel_audio_{phone_number}_{timestamp}.wav"
        
        # B·ªè lock - thu √¢m tr·ª±c ti·∫øp
        log("B·∫Øt ƒë·∫ßu thu √¢m tr·ª±c ti·∫øp...")
        
        p = pyaudio.PyAudio()
        
        stream = p.open(format=FORMAT,
                       channels=CHANNELS, 
                       rate=RATE,
                       input=True,
                       frames_per_buffer=CHUNK)
        
        log("ƒêang thu √¢m...")
        frames = []
        
        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
            data = stream.read(CHUNK)
            frames.append(data)
        
        stream.stop_stream()
        stream.close()
        
        # L∆∞u file WAV
        wf = wave.open(wave_filename, 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))
        wf.close()
        p.terminate()
        
        log("Ho√†n th√†nh thu √¢m, b·∫Øt ƒë·∫ßu ph√¢n t√≠ch Professional MFCC + DTW...")
        
        # Ph√¢n t√≠ch v·ªõi Professional MFCC + DTW (Option 7 style)
        result = analyze_audio_with_templates(wave_filename, log_callback)
        
        log(f"üíæ ƒê√£ l∆∞u audio: {wave_filename}")
        
        return result
            
    except Exception as e:
        log(f"L·ªói thu √¢m v√† ph√¢n t√≠ch: {str(e)}")
        return "HOAT DONG"  # Conservative fallback


def compare_audio_files_simple(file1: str, file2: str, threshold: float = 0.3) -> bool:
    """
    So s√°nh 2 file √¢m thanh ƒë∆°n gi·∫£n, tr·∫£ v·ªÅ True n·∫øu gi·ªëng nhau
    S·ª≠ d·ª•ng thu·∫≠t to√°n correlation c∆° b·∫£n
    """
    try:
        # ƒê·ªçc file WAV
        def read_wav_file(filename):
            with wave.open(filename, 'rb') as wf:
                frames = wf.readframes(wf.getnframes())
                audio_data = np.frombuffer(frames, dtype=np.int16)
                # Chuy·ªÉn stereo th√†nh mono
                if wf.getnchannels() == 2:
                    audio_data = audio_data.reshape(-1, 2)
                    audio_data = np.mean(audio_data, axis=1)
                return audio_data, wf.getframerate()
        
        audio1, rate1 = read_wav_file(file1)
        audio2, rate2 = read_wav_file(file2)
        
        if audio1 is None or audio2 is None or rate1 != rate2:
            return False
        
        # Chu·∫©n h√≥a
        audio1 = audio1.astype(np.float64) - np.mean(audio1)
        audio2 = audio2.astype(np.float64) - np.mean(audio2)
        
        if np.std(audio1) > 0:
            audio1 = audio1 / np.std(audio1)
        if np.std(audio2) > 0:
            audio2 = audio2 / np.std(audio2)
        
        # So s√°nh ƒëo·∫°n 5 gi√¢y ƒë·∫ßu ƒë·ªÉ tƒÉng t·ªëc
        segment_length = min(rate1 * 5, len(audio1), len(audio2))
        seg1 = audio1[:segment_length]
        seg2 = audio2[:segment_length]
        
        # Cross-correlation
        correlation_full = correlate(seg1, seg2, mode='full')
        max_corr = np.max(np.abs(correlation_full)) / len(seg1)
        
        # Direct correlation
        min_length = min(len(audio1), len(audio2))
        direct_corr = np.corrcoef(audio1[:min_length], audio2[:min_length])[0, 1]
        if np.isnan(direct_corr):
            direct_corr = 0
        
        # ƒêi·ªÉm s·ªë t·ªïng h·ª£p
        final_score = (max_corr * 0.6 + abs(direct_corr) * 0.4)
        
        return final_score >= threshold
        
    except Exception:
        return False



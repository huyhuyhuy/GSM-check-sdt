# ğŸš€ ModelPool - Load Balancing cho 30 GSM Instances

## ğŸ¯ Váº¥n Ä‘á»

### Scenario 1: Má»—i instance load model riÃªng (TrÆ°á»›c Ä‘Ã¢y)
```
30 GSM instances Ã— 1 model/instance = 30 models
RAM: ~1GB/model Ã— 30 = ~30GB
```
âŒ **Váº¥n Ä‘á»**: Tá»‘n RAM khá»§ng khiáº¿p!

### Scenario 2: Táº¥t cáº£ dÃ¹ng chung 1 model (Cáº£i tiáº¿n láº§n 1)
```
30 GSM instances â†’ 1 shared model
RAM: ~1GB
```
âœ… **Æ¯u Ä‘iá»ƒm**: Tiáº¿t kiá»‡m RAM tá»‘i Ä‘a (97%)
âŒ **Váº¥n Ä‘á»**: **BOTTLENECK nghiÃªm trá»ng!**
- 30 threads cÃ¹ng chá» 1 model
- Chá»‰ 1 thread xá»­ lÃ½ táº¡i 1 thá»i Ä‘iá»ƒm
- 29 threads khÃ¡c pháº£i Ä‘á»£i
- Tá»‘c Ä‘á»™ cháº­m nhÆ° rÃ¹a ğŸ¢

### Scenario 3: Model Pool vá»›i 4 models (Giáº£i phÃ¡p tá»‘i Æ°u) â­
```
30 GSM instances â†’ Pool of 4 models
RAM: ~1GB/model Ã— 4 = ~4GB
Load: 30 threads / 4 models = 7.5 threads/model
```
âœ… **Æ¯u Ä‘iá»ƒm**:
- Tiáº¿t kiá»‡m RAM: 87% (4GB vs 30GB)
- KhÃ´ng bottleneck: 4 models xá»­ lÃ½ song song
- Tá»‘c Ä‘á»™ tÄƒng ~7.5x so vá»›i 1 model
- Load balancing tá»± Ä‘á»™ng

---

## ğŸ—ï¸ Kiáº¿n trÃºc ModelPool

### 1. Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ModelPool                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Processor (shared)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Wav2Vec2Processor (1 instance)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â”‚  Model Pool (4 models)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Model 1  â”‚ â”‚ Model 2  â”‚ â”‚ Model 3  â”‚ â”‚ Model 4  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                          â”‚
â”‚  Queue (FIFO)                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Available Models: [M1, M2, M3, M4]             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Flow

```
Thread 1 â”€â”€â”
Thread 2 â”€â”€â”¤
Thread 3 â”€â”€â”¤
   ...     â”œâ”€â”€â†’ get_model() â”€â”€â†’ Queue â”€â”€â†’ Model 1 â”€â”€â†’ Use â”€â”€â†’ release_model()
Thread 28 â”€â”¤                            â”œâ†’ Model 2                    â”‚
Thread 29 â”€â”¤                            â”œâ†’ Model 3                    â”‚
Thread 30 â”€â”˜                            â””â†’ Model 4                    â”‚
                                                                       â”‚
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                                    Back to Queue
```

---

## ğŸ’» Code Implementation

### 1. ModelPool Class

```python
class ModelPool:
    def __init__(self, pool_size: int = 4):
        self._pool_size = pool_size
        self._processor = None  # Shared processor
        self._model_pool = []   # List of models
        self._model_queue = Queue()  # Available models queue
        
    def get_model(self):
        """Láº¥y model tá»« pool (blocking náº¿u pool Ä‘áº§y)"""
        if not self._loaded:
            self._load_pool()
        
        # Block until a model is available
        model = self._model_queue.get()
        return self._processor, model, self._device
    
    def release_model(self, model):
        """Tráº£ model vá» pool"""
        self._model_queue.put(model)
```

### 2. Usage trong GSMInstance

```python
def _transcribe_audio(self, wav_file):
    # Láº¥y model tá»« pool
    processor, model, device = model_manager.get_model()
    
    try:
        # Use model
        speech, rate = librosa.load(wav_file, sr=16000)
        input_values = processor(speech, ...).to(device)
        
        with torch.no_grad():
            logits = model(input_values).logits
        
        result = processor.batch_decode(...)
        return result[0]
        
    finally:
        # QUAN TRá»ŒNG: Tráº£ model vá» pool
        model_manager.release_model(model)
```

---

## ğŸ“Š Performance Analysis

### Vá»›i 30 GSM instances Ä‘á»“ng thá»i:

#### Scenario 1: Má»—i instance load riÃªng
```
RAM: 30GB
Tá»‘c Ä‘á»™: Nhanh (má»—i instance cÃ³ model riÃªng)
Váº¥n Ä‘á»: Tá»‘n RAM khá»§ng khiáº¿p
```

#### Scenario 2: 1 model shared
```
RAM: 1GB (tiáº¿t kiá»‡m 97%)
Tá»‘c Ä‘á»™: Ráº¤T CHáº¬M (bottleneck)
Thá»i gian: 30 Ã— T (tuáº§n tá»±)
Váº¥n Ä‘á»: Bottleneck nghiÃªm trá»ng
```

#### Scenario 3: Pool of 4 models â­
```
RAM: 4GB (tiáº¿t kiá»‡m 87%)
Tá»‘c Ä‘á»™: Nhanh (song song)
Thá»i gian: ~8 Ã— T (30/4 = 7.5 batches)
Váº¥n Ä‘á»: KHÃ”NG
```

### TÃ­nh toÃ¡n cá»¥ thá»ƒ:

Giáº£ sá»­ má»—i STT request máº¥t 1 giÃ¢y:

| Scenario | RAM | Thá»i gian xá»­ lÃ½ 30 requests | Tá»‘c Ä‘á»™ |
|----------|-----|----------------------------|--------|
| 30 models riÃªng | 30GB | 1s (song song) | âš¡âš¡âš¡âš¡âš¡ |
| 1 model shared | 1GB | 30s (tuáº§n tá»±) | ğŸ¢ |
| 4 models pool | 4GB | 8s (4 batches) | âš¡âš¡âš¡âš¡ |

**Káº¿t luáº­n**: Pool of 4 models lÃ  **sweet spot** - cÃ¢n báº±ng tá»‘t nháº¥t!

---

## ğŸ”§ Configuration

### Chá»n pool size phÃ¹ há»£p:

```python
# CÃ´ng thá»©c: pool_size = num_instances / 7-10

# 20 instances
model_manager = ModelPool(pool_size=3)

# 30 instances (recommended)
model_manager = ModelPool(pool_size=4)

# 40 instances
model_manager = ModelPool(pool_size=5)

# 50+ instances
model_manager = ModelPool(pool_size=6)
```

### Trade-off:

| Pool Size | RAM | Performance | Bottleneck Risk |
|-----------|-----|-------------|-----------------|
| 1 | Tháº¥p nháº¥t | Cháº­m nháº¥t | Cao nháº¥t |
| 2 | Tháº¥p | Cháº­m | Cao |
| 3 | Trung bÃ¬nh | Tá»‘t | Trung bÃ¬nh |
| **4** | **Tá»‘t** | **Ráº¥t tá»‘t** | **Tháº¥p** â­ |
| 5 | Cao | Ráº¥t tá»‘t | Ráº¥t tháº¥p |
| 10+ | Ráº¥t cao | Tá»‘t nháº¥t | KhÃ´ng |

---

## ğŸ§ª Testing

### Test vá»›i 30 threads:

```bash
python test_model_manager.py
```

Káº¿t quáº£ mong Ä‘á»£i:
```
=== Test 3: Thread Safety & Load Balancing ===
ğŸš€ Táº¡o 30 threads Ä‘á»“ng thá»i (giáº£ láº­p 30 GSM instances)...
   Pool size: 4 models

ğŸ“Š Káº¿t quáº£:
   - Tá»•ng thá»i gian: ~8s
   - Sá»‘ processor instances: 1 (expected: 1)
   - Sá»‘ model instances: 4 (expected: 4)
   - Max wait time: 0.XXXs
   - Avg wait time: 0.XXXs

âœ… Processor Ä‘Æ°á»£c share (1 instance)
âœ… Pool cÃ³ 4 models nhÆ° mong Ä‘á»£i
âœ… Load balancing hoáº¡t Ä‘á»™ng tá»‘t
âœ… Thread-safe hoáº¡t Ä‘á»™ng Ä‘Ãºng
```

---

## ğŸ“ˆ Statistics

ModelPool cung cáº¥p statistics real-time:

```python
stats = model_manager.get_statistics()

print(f"Pool size: {stats['pool_size']}")
print(f"Total requests: {stats['total_requests']}")
print(f"Avg wait time: {stats['avg_wait_time']:.3f}s")
print(f"Available models: {stats['available_models']}")
print(f"Busy models: {stats['busy_models']}")
```

---

## ğŸ¯ Best Practices

### 1. LuÃ´n release model
```python
# âŒ BAD - KhÃ´ng release
processor, model, device = model_manager.get_model()
result = transcribe(model, audio)
# Model khÃ´ng Ä‘Æ°á»£c tráº£ vá» pool â†’ Leak!

# âœ… GOOD - Release trong finally
processor, model, device = model_manager.get_model()
try:
    result = transcribe(model, audio)
finally:
    model_manager.release_model(model)
```

### 2. Sá»­ dá»¥ng context manager (tÆ°Æ¡ng lai)
```python
# âœ… BEST - Auto release
with get_model_context() as (processor, model, device):
    result = transcribe(model, audio)
# Model tá»± Ä‘á»™ng Ä‘Æ°á»£c release
```

### 3. Monitor statistics
```python
# Äá»‹nh ká»³ check statistics
stats = model_manager.get_statistics()
if stats['avg_wait_time'] > 1.0:
    print("âš ï¸ Pool cÃ³ thá»ƒ cáº§n tÄƒng size!")
```

---

## ğŸš€ Káº¿t luáº­n

### ModelPool giáº£i quyáº¿t Ä‘Æ°á»£c:
âœ… Tiáº¿t kiá»‡m RAM (87% so vá»›i khÃ´ng pool)
âœ… TrÃ¡nh bottleneck (4 models xá»­ lÃ½ song song)
âœ… Load balancing tá»± Ä‘á»™ng
âœ… Thread-safe
âœ… Dá»… scale (chá»‰ cáº§n tÄƒng pool_size)

### PhÃ¹ há»£p cho:
âœ… 20-50 GSM instances
âœ… Há»‡ thá»‘ng cáº§n xá»­ lÃ½ Ä‘á»“ng thá»i cao
âœ… RAM háº¡n cháº¿ nhÆ°ng cáº§n performance tá»‘t

### KhÃ´ng phÃ¹ há»£p cho:
âŒ < 10 instances (dÃ¹ng 1-2 models lÃ  Ä‘á»§)
âŒ RAM khÃ´ng giá»›i háº¡n (cÃ³ thá»ƒ dÃ¹ng model riÃªng cho má»—i instance)

---

**ModelPool = Smart Cache + Load Balancing + Thread Safety + Performance!** ğŸš€

